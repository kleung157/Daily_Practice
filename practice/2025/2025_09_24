Date: 09/24/2025

############################

Website:
StrataScratch - ID 2074

Difficulty:
Medium

Question Type:
R

Question:
Natera - Monthly Churn Rate
Calculate the churn rate of September 2021 in percentages. 
The churn rate is the difference between the number of customers on the first day of the month and on the last day of the month, divided by the number of customers on the first day of a month.
Assume that if customer's contract_end is NULL, their contract is still active. 
Additionally, if a customer started or finished their contract on a certain day, they should still be counted as a customer on that day.

Data Dictionary:
Table name = 'natera_subscriptions'
user_id: numeric (num)
contract_start: POSIXct, POSIXt (dt)
contract_end: POSIXct, POSIXt (dt)

Code:
Solution #1
## Question:
# Calculate the churn rate of September 2021 in percentages.
# The churn rate is the difference between the number of customers on the first day of the month
# and on the last day of the month, divided by the number of customers on the first day of a month.
# Assume that if customer's contract_end is NULL, their contract is still active.
# Additionally, if a customer started or finished their contract on a certain day,
# they should be still counted as a customer on that day.

## Output:
# churn_rate

## Import libraries:
#install.packages(tidyverse)
library(tidyverse)

## Load and preview data:
#natera_subscriptions <- read_csv('natera_subscriptions.csv')
subscriptions_df <- data.frame(natera_subscriptions)
head(subscriptions_df, 5)

## Check datatypes, nulls, and rows:
# Nulls - contract_end(1)
# Rows - 6
data.frame(lapply(subscriptions_df, class))
colSums(is.na(subscriptions_df))
nrow(subscriptions_df)

## Iteration:
# Calculate the churn rate of September 2021 in percentages.
# The churn rate is the difference between the number of customers on the first day of the month
# and on the last day of the month, divided by the number of customers on the first day of a month.
# Assume that if customer's contract_end is NULL, their contract is still active.
# Additionally, if a customer started or finished their contract on a certain day,
# they should be still counted as a customer on that day.
# churn_rate

# 1. Establish first day of month as start_date and last day of month as end_date
#    Convert date to correct format
start_date <- as.POSIXct('2021-09-01')
end_date <- as.POSIXct('2021-09-30')

# 2. Filter for number of customers on first day of month and last day of month in separate dataframes
first_day_customers <- subscriptions_df %>%
    filter(
        (contract_start <= start_date) &
        ((contract_end >= start_date) | (is.na(contract_end)))    # Include NULLs
    )
    
last_day_customers <- subscriptions_df %>%
    filter(
        (contract_start <= end_date) &
        ((contract_end >= end_date) | (is.na(contract_end)))    # Include NULLs
    )

# 3. Calculate churn rate using number of rows for each DataFrame
#    Churn rate = (first_day - last_day) / (first_day)
result_df <- data.frame(
    churn_rate = 
        round(
            100.0 * (nrow(first_day_customers) - nrow(last_day_customers)) /
            (nrow(first_day_customers))
        , digits = 2)
)

## Result:
print(paste("Churn Rate for September 2021:", result_df, "%"))

Notes:
- To convert a string to date in format "YYYY-MM-DD" use as.POSIXct() function.
- strftime() function converts a date object to a chracter string
  ex.
      start_date <- strftime('2021-09-01', "%Y-%m-%d")
- print(paste("text", df)) is similar to Python printing text then the dataframe
  ex.
      print(paste("Churn Rate for September 2021:", result_df, "%"))
- sum() function can be used to add up all the True and False statements and account for filters
  ex.
      customers_start <- sum(
          subscriptions_df$contract_start <= start_date &
          (subscriptions_df$contract_end >= start_date | is.na(subscriptions_df$contract_end))
      )
- Initially had forgotten how to convert a string date to an actual date for the filtering of dates in a
  column. Tried to use as.Date() but the date format was not correct compared to as.POSIXct() or strftime().
  strftime() I thought creates a date but it's actually a character string. as.POSIXct() is the correct way
  to get an object in a date datatype.
- When filtering using & or |, make sure that filters are grouped together in paranthesis to avoid having
  an incorrect interpretation of filters. The or | seems to be notorious for needing it more than the &.

############################

Website:
StrataScratch - ID 2113

Difficulty:
Medium

Question Type:
Python

Question:
Yelp - Extremely Late Delivery
To remain competitive, the company you work with must reduce the number of extremely late deliveries.
A delivery is flagged as extremely late if the actual delivery time is more than 20 minutes (not inclusive) after the predicted delivery time.
You have been asked to calculate the percentage of orders that arrive extremely late each month.
Your output should include the month in the format 'YYYY-MM' and the percentage of extremely late orders as a percentage of all orders placed in that month.

Data Dictionary:
Table name = 'delivery_orders'
delivery_id: object (str)
order_placed_time: datetime64 (dt)
predicted_delivery_time: datetime64 (dt)
actual_delivery_time: datetime64 (dt)
delivery_rating: float64 (flt)
driver_id: object (str)
restaurant_id: object (str)
consumer_id: object (str)

Code:
Solution #1
## Question:
# To remain competitive, the company you work with must reduce the number of extremely late deliveries.
# A delivery is flagged as extremely late if the actual delivery time is more than 20 minutes (not inclusive)
# after the predicted delivery time.
# You have been asked to calculate the percentage of orders that arrive extremely late each month.
# Output should include the month in format 'YYYY-MM' and the percentage of extremely late orders as a 
# percentage of all orders placed in that month.

## Output:
# year_month, extremely_late_order_percentage

## Import libraries:
import pandas as pd
import numpy as np

## Load and preview data:
#delivery_orders = pd.read_csv('delivery_orders.csv')
orders_df = pd.DataFrame(delivery_orders)
orders_df.head(5)

## Check datatypes, nulls, and rows:
# Nulls - actual_delivery_time(3), delivery_rating(3)
# Rows - 50
#orders_df.info()
#orders_df.isna().sum()

## Iteration:
# To remain competitive, the company you work with must reduce the number of extremely late deliveries.
# A delivery is flagged as extremely late if the actual delivery time is more than 20 minutes (not inclusive)
# after the predicted delivery time.
# You have been asked to calculate the percentage of orders that arrive extremely late each month.
# Output should include the month in format 'YYYY-MM' and the percentage of extremely late orders as a 
# percentage of all orders placed in that month.
# year_month, extremely_late_order_percentage

# 1. Extract year and month from order_placed_time to create column in 'YYYY-MM' format
orders_df['year_month'] = orders_df['order_placed_time'].dt.to_period('M')

# 2. Calculate minutes to delivery between predicted_delivery_time and actual_delivery_time
#    Convert time interval to seconds then divide by 60 to get minutes
orders_df['minutes_to_delivery'] = (
    (orders_df['actual_delivery_time'] - orders_df['predicted_delivery_time']).dt.total_seconds() / 60
)

# 3. Categorize orders that are more than 20 minutes as 1 if late, 0 if not late
orders_df['late'] = np.where(orders_df['minutes_to_delivery'] > 20, 1, 0)

# 4. Count total deliveries and sum late deliveries for each year_month
result_df = (
    orders_df.groupby('year_month')
    .agg(
        total_deliveries=('delivery_id','count'),
        late_deliveries=('late', 'sum')
    )
    .reset_index()
)

# 5. Calculate extremely late order percentage, percentage = late_deliveries / total_deliveries
result_df['extremely_late_order_percentage'] = (
    round(
        100.0 * (result_df['late_deliveries'] / result_df['total_deliveries'])
    , 2)
)

# 6. Select relevant columns and sort year month ASC
result_df = result_df[['year_month', 'extremely_late_order_percentage']].sort_values(by='year_month', ascending=True)

## Result:
print("Percentage of orders that arrived extremely late each month:")
result_df

Notes:
- For converting a time interval between two datetimes use .dt.total_seconds() then perform arithmetic for
  necessary conversion to say minutes or hours.
  ex. 
      orders_df['actual_delivery_time'] - orders_df['order_placed_time']).dt.total_seconds() / 60
- When performing multiple aggregations, it's help to categorize a column into 1 or 0 to be able to sum
  in addition to count different columns. It's an approach I use in SQL a lot but never really thought about
  implementing naturally in Python when performing groupby aggregations.
- There were 3 null values for actual_delivery_time, I wanted to fill them in with the maximum actual delivery
  time because they technically were orders that didn't get delivered but the problem states that "if the
  actual delivery time is more than 20 minutes". There were no minutes provided and no mentions about nulls in
  this column beyond that so didn't alter the nulls but categorized these orders as not late according to the
  problem's limitations.

############################

Website:
StrataScratch - ID 9790

Difficulty:
Hard

Question Type:
SQL

Question:
Meta - Find the number of processed and not-processed complaints of each type
Find the number of processed and non-processed complaints of each type.
Replace NULL values with 0s.
Output the complaint type along with the number of processed and not-processed complaints.

Data Dictionary:
Table name = 'facebook_complaints'
complaint_id: bigint (int)
processed: boolean (bool)
type: bigint (int)

Code:
Solution #1
-- Question:
-- Find the number of processed and non-processed complaints of each type.
-- Replace NULL values with 0s.
-- Output the complaint type along with the number of processed and not-processed complaints.

-- Output:
-- type, processed_count, nonprocessed_count

-- Preview data:
SELECT * FROM facebook_complaints LIMIT 5;

-- Check nulls and rows:
-- Nulls - 0
-- Rows - 6
SELECT
    SUM(CASE WHEN complaint_id IS NULL THEN 1 ELSE 0 END) AS col1,
    SUM(CASE WHEN processed IS NULL THEN 1 ELSE 0 END) AS col2,
    SUM(CASE WHEN type IS NULL THEN 1 ELSE 0 END) AS col3,
    COUNT(*) AS total_rows
FROM facebook_complaints;

-- Iteration:
-- Find the number of processed and non-processed complaints of each type.
-- Replace NULL values with 0s.
-- Output the complaint type along with the number of processed and not-processed complaints.
-- type, processed_count, nonprocessed_count
-- 1. Count number of processed and non-processed complaints for each type using CASE WHEN filters
SELECT 
    type,
    COUNT(CASE WHEN processed = TRUE THEN complaint_id END) AS processed_count,
    COUNT(CASE WHEN processed = FALSE THEN complaint_id END) AS nonprocessed_count
FROM facebook_complaints
GROUP BY type
ORDER BY type;

-- Result:
-- 1. Count number of processed and non-processed complaints for each type using CASE WHEN filters
SELECT 
    type,
    COUNT(
        CASE WHEN processed = TRUE THEN complaint_id END
    ) AS processed_count,
    COUNT(
        CASE WHEN processed = FALSE THEN complaint_id END
    ) AS nonprocessed_count
FROM 
    facebook_complaints
GROUP BY 
    type
ORDER BY 
    type;

Notes:
- When performing null checks on the dataset, there were no nulls present so the problem asking to replace
  NULL values with 0s wasn't relevant for solving. In the case of using COUNT() if anything did end up being
  not counted then it would come out to 0 instead of NULL. If I had used SUM() then I would have the ELSE
  clause be 0. COUNT() doesn't need the ELSE clause when filtering in a CASE WHEN statement.
- There were only 6 rows for this dataset, for a hard SQL problem it definitely was not hard by any means.
  Perhaps a lot of the data was omitted and this question ended up being more of a easy-medium range

############################
